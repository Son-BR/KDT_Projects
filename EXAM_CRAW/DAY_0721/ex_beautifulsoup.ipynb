{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup 라이브러리\n",
    " - HTML 문서나 XML 문서를 탐색해서 원하는 부분만 쉽게 추출\n",
    " - BeautifulSoup 객체 생성\n",
    "  - soup = BeautifulSoup(HTML/XML 문서, 구문 분석기)\n",
    "    - 구문 분석기 : html.parser, lxml, html5lib 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('https://www.daangn.com/hot_articles')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_example = '''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>BeautifulSoup 활용</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1 id=\"heading\">Heading 1</h1>\n",
    "    <p>Paragraph</p>\n",
    "    <span class=\"red\">BeautifulSoup Library Examples!</span>\n",
    "    <div id=\"link\">\n",
    "        <a class=\"external_link\" href=\"www.google.com\">google</a>\n",
    "        <div id=\"class1\">\n",
    "            <p id=\"first\">class1's first paragraph</p>\n",
    "            <a class=\"external_link\" href=\"www.naver.com\">naver</a>\n",
    "            <p id=\"second\">class1's second paragraph</p>\n",
    "            <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
    "            <p id=\"third\">class1's third paragraph</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    <div id=\"text_id2\">\n",
    "        Example page\n",
    "        <p>g</p>\n",
    "    </div>\n",
    "    <h1 id=\"footer\">Footer</h1>\n",
    "</body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 태그를 사용하여 요소에 직접 접근하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>BeautifulSoup 활용</title>\n",
      "BeautifulSoup 활용\n",
      "BeautifulSoup 활용\n"
     ]
    }
   ],
   "source": [
    "# <title> 태그에 접근(soup.태그명)\n",
    "soup = BeautifulSoup(html_example, 'html.parser')\n",
    "\n",
    "print(soup.title)            # <title> 태그 전체를 가져옴\n",
    "print(soup.title.text)       # <title>태그의 텍스트만 리턴\n",
    "print(soup.title.get_text()) # .text와 동일한 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "<title>BeautifulSoup 활용</title>\n",
      "</head>\n"
     ]
    }
   ],
   "source": [
    "# 태그명.parent: 해당 태그를 포함하고 있는 부모\n",
    "print(soup.title.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body>\n",
      "<h1 id=\"heading\">Heading 1</h1>\n",
      "<p>Paragraph</p>\n",
      "<span class=\"red\">BeautifulSoup Library Examples!</span>\n",
      "<div id=\"link\">\n",
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "<div id=\"class1\">\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<a class=\"external_link\" href=\"www.naver.com\">naver</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<p id=\"third\">class1's third paragraph</p>\n",
      "</div>\n",
      "</div>\n",
      "<div id=\"text_id2\">\n",
      "        Example page\n",
      "        <p>g</p>\n",
      "</div>\n",
      "<h1 id=\"footer\">Footer</h1>\n",
      "</body>\n"
     ]
    }
   ],
   "source": [
    "# <body>태그에 접근\n",
    "print(soup.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"heading\">Heading 1</h1>\n",
      "Heading 1\n"
     ]
    }
   ],
   "source": [
    "# <h1>태그 접근 : 동일한 태그가 여러 개 있는 경우, 첫 번째 요소를 추출\n",
    "print(soup.h1)\n",
    "print(soup.h1.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n"
     ]
    }
   ],
   "source": [
    "# <a> 태그 접근 : 첫 번째 <a> 태그 요소 추출\n",
    "print(soup.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find() 함수\n",
    " - 파라미터 : find(tag(태그), attrs(속성), recursive, text, keywords)\n",
    " - 해당 조건에 맞는 맨 처음 검색 결과만 추출\n",
    " - 이름, 속성, 속성값을 이용하여 원하는 태그를 찾을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div id=\"link\">\n",
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "<div id=\"class1\">\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<a class=\"external_link\" href=\"www.naver.com\">naver</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<p id=\"third\">class1's third paragraph</p>\n",
      "</div>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('div'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div id=\"text_id2\">\n",
      "        Example page\n",
      "        <p>g</p>\n",
      "</div>\n",
      "<div id=\"text_id2\">\n",
      "        Example page\n",
      "        <p>g</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "# 여러 <div> 태그 중 특정 속성을 가지는 항목 추출 : 딕셔터리 형태로 입력\n",
    "print(soup.find('div', {'id':'text_id2'}))\n",
    "               # tag    속성    속성값\n",
    "               # <div id=\"text_id2\">\n",
    "\n",
    "print(soup.find('div',attrs={'id':'text_id2'}))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Example page\n",
      "        g\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 추출된 요소에서 텍스트만 가져옴 : .text 또는 get_text()\n",
    "div_text = soup.find('div', {'id':'text_id2'})\n",
    "\n",
    "print(div_text.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div id=\"class1\">\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<a class=\"external_link\" href=\"www.naver.com\">naver</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<p id=\"third\">class1's third paragraph</p>\n",
      "</div>\n",
      "\n",
      "\n",
      "class1's first paragraph\n",
      "naver\n",
      "class1's second paragraph\n",
      "Page1\n",
      "class1's third paragraph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "div_first=soup.find('div',attrs={'id':'class1'})\n",
    "print(div_first)\n",
    "print()\n",
    "print(div_first.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n"
     ]
    }
   ],
   "source": [
    "# <a>태그 및 <a> 태그의 href 속성 추출\n",
    "# <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
    "\n",
    "# href 속성으로 찾기\n",
    "href_link2 = soup.find('a', {'href':'/pages/page1.html'})\n",
    "href_link2 = soup.find('a', href='/pages/page1.html')  \n",
    "\n",
    "# class 속성으로 찾기\n",
    "href_link = soup.find('a', {'class':'internal_link'})   # 딕셔너리 형태\n",
    "href_link = soup.find('a', class_='internal_link')      # class는 파이썬 예약어라서 '_'추가\n",
    "\n",
    "\n",
    "print(href_link)\n",
    "print(href_link2)\n",
    "\n",
    "# print(href_link['href'])      # <a>태그 내부 href속성의 값(url)을 추출\n",
    "# print(href_link.get('href'))  # ['href']와 동일 기능\n",
    "# print(href_link.text)         # <a> Page1 </a>태그 내부의 텍스트(Page1) 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([['internal_link'], '/pages/page1.html'])\n"
     ]
    }
   ],
   "source": [
    "# <a> 태그 내부의 모든 속성의 값 가져오기: dict의 values() 호출\n",
    "print(href_link.attrs.values())     # 모든 속성값 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['internal_link'] /pages/page1.html\n"
     ]
    }
   ],
   "source": [
    "values = list(href_link.attrs.values()) # dictionary의 값들을 리스트로 변경\n",
    "print(values[0], values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "google\n"
     ]
    }
   ],
   "source": [
    "# href 속성의 값이 ‘www.google.com’인 항목 검색\n",
    "href_value = soup.find(attrs={'href' : 'www.google.com'}) # 태그생략시 'attrs=' 명시\n",
    "print(href_value)\n",
    "print(href_value.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "span tag: <span class=\"red\">BeautifulSoup Library Examples!</span>\n",
      "attrs: {'class': ['red']}\n",
      "value: ['red']\n",
      "text: BeautifulSoup Library Examples!\n"
     ]
    }
   ],
   "source": [
    "# span 태그의 속성 가져오기\n",
    "# <span class=\"red\">BeautifulSoup Library Examples!</span>\n",
    "\n",
    "span_tag=soup.find('span')\n",
    "\n",
    "print('span tag:', span_tag)\n",
    "print('attrs:', span_tag.attrs) # attribute(속성) 추출, 딕셔너리형태로 리턴\n",
    "\n",
    "print('value:', span_tag.attrs['class']) # class 속성의 값 추출\n",
    "print('text:', span_tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find_all() 함수\n",
    " - 검색된 모든 태그를 리턴(리스트 형태)\n",
    " - 파라미터 : find_all(tag, attrs, recursive, text, limit, keywords)\n",
    " - tag: HTML 태그, 태그 이름으로 이루어진 리스트 전달\n",
    " - attrs: 속성, 파이썬 딕셔너리를 받음 (or 속성)\n",
    " - recursive: 재귀 검색\n",
    "   - True: 모든 문서에서 태그를 검색(자식, 자식의 자식을 검색)\n",
    "   - False: 최상의 태그만 검색\n",
    " - text: 텍스트 콘텐츠와 일치하는 문장 검색\n",
    " – limit: 일치하는 검색어를 몇 개까지 찾을 것인지 설정\n",
    "   - limit = None : 제한 없음 (모두 검색)\n",
    "   - limit = 1 : find() 메소드와 동일\n",
    " - keyword: BeautifulSoup 자체 기능과 중복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.find_all('span', {'class': {'green', 'red'}}) # ‘green’ or ‘red’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the prince count:  0\n"
     ]
    }
   ],
   "source": [
    "princeList = bs.find_all(text='the prince')\n",
    "print('the prince count: ', len(princeList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div id=\"link\">\n",
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "<div id=\"class1\">\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<a class=\"external_link\" href=\"www.naver.com\">naver</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<p id=\"third\">class1's third paragraph</p>\n",
      "</div>\n",
      "</div>, <div id=\"class1\">\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<a class=\"external_link\" href=\"www.naver.com\">naver</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<p id=\"third\">class1's third paragraph</p>\n",
      "</div>, <div id=\"text_id2\">\n",
      "        Example page\n",
      "        <p>g</p>\n",
      "</div>]\n"
     ]
    }
   ],
   "source": [
    "# 모든 div 태그 검색\n",
    "div_tags = soup.find_all('div')\n",
    "print(div_tags)         # 전체 div 태그를 모두 검색 (리스트 형태로 반환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "<div id=\"text_id2\">\n",
      "        Example page\n",
      "        <p>g</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "print(len(div_tags))\n",
    "print(div_tags[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "url:www.google.com, text:google\n",
      "\n",
      "<a class=\"external_link\" href=\"www.naver.com\">naver</a>\n",
      "url:www.naver.com, text:naver\n",
      "\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "url:/pages/page1.html, text:Page1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모든 <a>태그 검색 및 속성 보기\n",
    "links = soup.find_all('a')\n",
    "\n",
    "for alink in links:\n",
    "    print(alink)\n",
    "    print('url:{0}, text:{1}'.format(alink['href'], alink.get_text()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"external_link\" href=\"www.google.com\">google</a>, <a class=\"external_link\" href=\"www.naver.com\">naver</a>, <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]\n",
      "\n",
      "[<p id=\"first\">class1's first paragraph</p>, <p id=\"third\">class1's third paragraph</p>]\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<p id=\"third\">class1's third paragraph</p>\n"
     ]
    }
   ],
   "source": [
    "# 특정 태그 중 여러 속성값을 한 번에 검색\n",
    "\n",
    "# <a>태그에서 class 속성값이 ‘external_link’, ‘internal_link’것만 검색 \n",
    "# => 리스트 형태로 추가\n",
    "link_tags = soup.find_all('a', {'class':['external_link', 'internal_link']})\n",
    "print(link_tags)\n",
    "\n",
    "print()\n",
    "# <p>태그의 id값이 ‘first’, ‘third’인 항목 검색\n",
    "p_tags = soup.find_all('p', {'id': ['first', 'third']})\n",
    "print(p_tags)\n",
    "for p in p_tags:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select(), select_one() 함수\n",
    "#### select() 함수\n",
    " - CSS selector로 tag객체를 찾아 리턴\n",
    " - 조건에 맞는 모든 태그를 리턴\n",
    "   - find_all()과 유사\n",
    "\n",
    "#### select_one() 함수\n",
    " - 조건에 맞는 첫 번째 태그만 리턴\n",
    "   - find()와 유사\n",
    "\n",
    "##### select_one()과 find() 차이점\n",
    " - find()\n",
    "   - 하위 태그를 찾을 때, 반복적으로 코드를 작성\n",
    "   - soup.find(‘div’).find(‘p’)\n",
    " - select()\n",
    "   - 하위 태그를 찾을 때, 직접 하위 경로 지정\n",
    "   - soup.select_one(‘div > p’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### select() 함수 사용법\n",
    " - 형태 : select(selector, namespaces=None, limit=None, **kwargs)\n",
    " - select(‘태그’)\n",
    "   - 해당 태그를 포함하는 모든 요소 리턴\n",
    " - select(‘태그#id이름’) 또는 select(‘#id이름’)\n",
    "   - 태그 내부의 id이름을 이용하여 검색: #id\n",
    " - select(‘태그.클래스이름’) 또는 select(‘.클래스이름’)\n",
    "   - 특정 태그에 포함된 클래스명 검색: 태그 이름은 생략 가능\n",
    "   - .클래스이름\n",
    " - select(‘상위태그 > 하위태그1 > 하위태그2’)\n",
    "   - 계층적으로 하위 태그 접근\n",
    " - select(‘태그[속성1=값1]’)\n",
    "   - 특정 태그의 속성과 속성값을 이용한 검색"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select_one() 함수 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "<title>BeautifulSoup 활용</title>\n",
      "</head>\n"
     ]
    }
   ],
   "source": [
    "# <head>태그 검색\n",
    "head = soup.select_one('head')\n",
    "print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"heading\">Heading 1</h1>\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 <h1>태그 검색\n",
    "h1 = soup.select_one('h1')\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"footer\">Footer</h1>\n"
     ]
    }
   ],
   "source": [
    "# <h1>태그의 id 검색 : #id\n",
    "# <h1>태그의 id가 \"footer＂인 항목 추출\n",
    "heading = soup.select_one('h1#footer')  # '#'=>id를 의미\n",
    "print(heading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"footer\">Footer</h1>\n"
     ]
    }
   ],
   "source": [
    "head = soup.select_one('#footer')\n",
    "print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "Page1\n",
      "/pages/page1.html\n"
     ]
    }
   ],
   "source": [
    "# 클래스 이름 검색 : 태그.클래스이름\n",
    "# <a class=“internal_link”> 검색\n",
    "\n",
    "class_link = soup.select_one('a.internal_link') # a의 'internal_link' class를 의미\n",
    "print(class_link)\n",
    "print(class_link.text)\n",
    "print(class_link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "class1's second paragraph\n"
     ]
    }
   ],
   "source": [
    "# 계층적 하위 태그 접근\n",
    "# (상위태그 > 하위태그) 형식으로 접근\n",
    "\n",
    "link1 = soup.select_one('div#link > a.external_link')\n",
    "print(link1)\n",
    "\n",
    "print()\n",
    "\n",
    "# (상위태그 하위태그) 형식으로 접근\n",
    "link2 = soup.select_one('div#class1 p#second')\n",
    "print(link2)\n",
    "print(link2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select() 함수 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1 id=\"heading\">Heading 1</h1>, <h1 id=\"footer\">Footer</h1>]\n"
     ]
    }
   ],
   "source": [
    "# 모든 <h1> 태그 검색\n",
    "h1_all = soup.select('h1')\n",
    "print(h1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.google.com\n",
      "www.naver.com\n",
      "/pages/page1.html\n"
     ]
    }
   ],
   "source": [
    "# 모든 url 링크 검색\n",
    "\n",
    "# html문서의 모든 <a> 태그의 href 값 추출\n",
    "url_links = soup.select('a')\n",
    "for link in url_links:\n",
    "    print(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"external_link\" href=\"www.naver.com\">naver</a>, <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]\n",
      "\n",
      "www.naver.com\n"
     ]
    }
   ],
   "source": [
    "# <div id=“class1”> 내부의 모든 url 검색\n",
    "div_urls = soup.select('div#class1 > a')\n",
    "print(div_urls)\n",
    "\n",
    "print()\n",
    "\n",
    "print(div_urls[0]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1 id=\"heading\">Heading 1</h1>, <h1 id=\"footer\">Footer</h1>]\n"
     ]
    }
   ],
   "source": [
    "# 여러 항목 검색하기\n",
    "\n",
    "# <h1>태그의 id가 ”heading”과 “footer”를 모두 검색 => 쉼표(,)로 나열함\n",
    "# <h1 id=\"heading”>과 <h1 id=\"footer”> 항목 가져오기\n",
    "h1 = soup.select('#heading, #footer')\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"external_link\" href=\"www.google.com\">google</a>, <a class=\"external_link\" href=\"www.naver.com\">naver</a>, <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]\n"
     ]
    }
   ],
   "source": [
    "# <a>태그의 class이름이 “external_link”와 ”internal_link” 모두 검색\n",
    "url_links = soup.select('a.external_link, a.internal_link')\n",
    "print(url_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"external_link\" href=\"www.google.com\">google</a>, <a class=\"external_link\" href=\"www.naver.com\">naver</a>, <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_anthem = '''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <title>애국가</title>\n",
    "</head>\n",
    "<body>\n",
    "    <div>\n",
    "        <p id=\"title\">애국가</p>\n",
    "        <p class=\"content\">\n",
    "            동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세.<br>\n",
    "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br>\n",
    "        </p>\n",
    "        <p class=\"content\">\n",
    "            남산 위에 저 소나무 철갑을 두른 듯 바람서리 불변함은 우리 기상일세.<br>\n",
    "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br>\n",
    "        </p>\n",
    "        <p class=\"content\">\n",
    "            가을 하늘 공활한데 높고 구름 없이 밝은 달은 우리 가슴 일편단심일세.<br>\n",
    "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br>\n",
    "        </p>\n",
    "        <p class=\"content\">\n",
    "            이 기상과 이 맘으로 충성을 다하여 괴로우나 즐거우나 나라 사랑하세.<br>\n",
    "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br>\n",
    "        </p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "애국가\n"
     ]
    }
   ],
   "source": [
    "# 제목과 가사 내용 추출\n",
    "\n",
    "# 제목\n",
    "bs4 = BeautifulSoup(national_anthem, 'html.parser')\n",
    "print(bs4.select_one('p#title').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"content\">\n",
      "            동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세.<br/>\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br/>\n",
      "</p>, <p class=\"content\">\n",
      "            남산 위에 저 소나무 철갑을 두른 듯 바람서리 불변함은 우리 기상일세.<br/>\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br/>\n",
      "</p>, <p class=\"content\">\n",
      "            가을 하늘 공활한데 높고 구름 없이 밝은 달은 우리 가슴 일편단심일세.<br/>\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br/>\n",
      "</p>, <p class=\"content\">\n",
      "            이 기상과 이 맘으로 충성을 다하여 괴로우나 즐거우나 나라 사랑하세.<br/>\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br/>\n",
      "</p>]\n",
      "\n",
      "\n",
      "            동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세.\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.\n",
      "\n",
      "\n",
      "            남산 위에 저 소나무 철갑을 두른 듯 바람서리 불변함은 우리 기상일세.\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.\n",
      "\n",
      "\n",
      "            가을 하늘 공활한데 높고 구름 없이 밝은 달은 우리 가슴 일편단심일세.\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.\n",
      "\n",
      "\n",
      "            이 기상과 이 맘으로 충성을 다하여 괴로우나 즐거우나 나라 사랑하세.\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 가사\n",
    "contents = bs4.select('p.content')\n",
    "\n",
    "print(contents)\n",
    "print()\n",
    "\n",
    "for content in contents:\n",
    "    print(content.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('EV_PY37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b873a8672c2d1bd0434cc4b24a8baf885b3ba4979d58ab55f0c4583a39586f40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
