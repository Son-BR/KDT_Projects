{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 청경채 잎 면적 증감률 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# copy 경고 무시\n",
    "pd.set_option('mode.chained_assignment',  None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로\n",
    "path_input='./data/train_input/'\n",
    "path_target='./data/train_target/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 만들기\n",
    "\n",
    "\n",
    "# input 데이터 전처리\n",
    "def input_data(file):\n",
    "    \n",
    "    path_input='./data/train_input/'\n",
    "    \n",
    "    # 파일 불러오기\n",
    "    df=pd.read_csv(path_input+file)\n",
    "    \n",
    "    \n",
    "    # 컬럼명 변경\n",
    "    df.columns=['시간', '내부온도관측치', '내부습도관측치', 'CO2관측치', 'EC관측치', '외부온도관측치', '외부습도관측치',\n",
    "       '펌프상태', '펌프작동남은시간', '최근분무량', '일간누적분무량', '냉방상태', '냉방작동남은시간', '난방상태',\n",
    "       '난방작동남은시간', '내부유동팬상태', '내부유동팬작동남은시간', '외부환기팬상태', '외부환기팬작동남은시간',\n",
    "       '화이트 LED상태', '화이트 LED작동남은시간', '화이트 LED동작강도', '레드 LED상태', '레드 LED작동남은시간',\n",
    "       '레드 LED동작강도', '블루 LED상태', '블루 LED작동남은시간', '블루 LED동작강도', '카메라상태', '냉방온도',\n",
    "       '난방온도', '기준온도', '난방부하', '냉방부하', '총추정광량', '백색광추정광량', '적색광추정광량',\n",
    "       '청색광추정광량']\n",
    "    \n",
    "    # 필요한 컬럼만 남기기\n",
    "    df1=df[['시간', '내부온도관측치', '내부습도관측치', 'CO2관측치', 'EC관측치',\n",
    "        '일간누적분무량', '백색광추정광량', '적색광추정광량', '청색광추정광량']]\n",
    "\n",
    "    # 결측치 제거\n",
    "    df1=df1.dropna()\n",
    "    \n",
    "    return df1\n",
    "\n",
    "# 데이터 일별 그룹화 후 평균\n",
    "def group_data(df):\n",
    "    \n",
    "    # 월,일만 남긴 후 일별로 그룹화\n",
    "    df['시간']=df['시간'].apply(lambda x : x[0:10])\n",
    "    df=df.groupby('시간')\n",
    "    \n",
    "    # 일별 최종 분무량\n",
    "    df_max=df['일간누적분무량'].max()\n",
    "    \n",
    "    # 일별 평균 및 누적분무량\n",
    "    df_mean=df.mean()\n",
    "    df_mean['일간누적분무량']=df_max\n",
    "    df_mean['DAY']=df.groups\n",
    "    \n",
    "    return df_mean\n",
    "\n",
    "# target 데이터 전처리\n",
    "def target_data():\n",
    "    path_target='./data/train_target/'\n",
    "\n",
    "    target_file=os.listdir(path_target)\n",
    "    target=pd.DataFrame()\n",
    "    \n",
    "    for i in target_file:\n",
    "        df=pd.read_csv(path_target+i)\n",
    "        df['시간']=pd.to_datetime(df['시간'])+datetime.timedelta(days=-1)\n",
    "        df['시간']=df['시간'].astype('object')\n",
    "        df['시간']=df['시간'].apply(lambda x : str(x)[0:10])\n",
    "        target=pd.concat([target, df], ignore_index=True)\n",
    "    target.columns=['DAY','rate']\n",
    "    \n",
    "    return target\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2=pd.read_csv(path_target+'CASE_01.csv')\n",
    "# df=input_data('CASE_01.csv')\n",
    "# pd.concat([group_data(df),df2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 9)\n",
      "(29, 9)\n",
      "(27, 9)\n",
      "(29, 9)\n",
      "(29, 9)\n",
      "(29, 9)\n",
      "(29, 9)\n",
      "(29, 9)\n",
      "(47, 9)\n",
      "(42, 9)\n",
      "(40, 9)\n",
      "(33, 9)\n",
      "(33, 9)\n",
      "(45, 9)\n",
      "(45, 9)\n",
      "(44, 9)\n",
      "(25, 9)\n",
      "(42, 9)\n",
      "(28, 9)\n",
      "(26, 9)\n",
      "(26, 9)\n",
      "(26, 9)\n",
      "(26, 9)\n",
      "(26, 9)\n",
      "(26, 9)\n",
      "(37, 9)\n",
      "(33, 9)\n",
      "(42, 9)\n",
      "(35, 9)\n",
      "(33, 9)\n",
      "(39, 9)\n",
      "(27, 9)\n",
      "(28, 9)\n",
      "(28, 9)\n",
      "(28, 9)\n",
      "(26, 9)\n",
      "(44, 9)\n",
      "(15, 9)\n",
      "(37, 9)\n",
      "(37, 9)\n",
      "(15, 9)\n",
      "(22, 9)\n",
      "(18, 9)\n",
      "(15, 9)\n",
      "(40, 9)\n",
      "(39, 9)\n",
      "(24, 9)\n",
      "(41, 9)\n",
      "(34, 9)\n",
      "(39, 9)\n",
      "(25, 9)\n",
      "(27, 9)\n",
      "(27, 9)\n",
      "(27, 9)\n",
      "(18, 9)\n",
      "(25, 9)\n",
      "(32, 9)\n",
      "(25, 9)\n"
     ]
    }
   ],
   "source": [
    "# data 생성\n",
    "\n",
    "input_file=os.listdir(path_input)\n",
    "\n",
    "data=pd.DataFrame()\n",
    "\n",
    "for i in input_file:\n",
    "    df=input_data(i)\n",
    "    \n",
    "    data=pd.concat([data, group_data(df)], ignore_index=True)\n",
    "    print(group_data(df).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18608\\1756831864.py:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  rate=rate.values.astype(np.float)[0]\n"
     ]
    }
   ],
   "source": [
    "# target 생성\n",
    "\n",
    "target_data=target_data()\n",
    "rate_list=[]\n",
    "for i in data['DAY']:\n",
    "    for j in target_data['DAY']:\n",
    "        if i==j:\n",
    "            rate=target_data[target_data['DAY']==i]['rate']\n",
    "            rate=rate.values.astype(np.float)[0]\n",
    "            rate_list.append(rate)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\PycharmProjects\\EXAM_ML\\ML_Project\\train02.ipynb 셀 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/EXAM_ML/ML_Project/train02.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray(data\u001b[39m.\u001b[39;49miloc[:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/EXAM_ML/ML_Project/train02.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m target\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray(rate_list)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/EXAM_ML/ML_Project/train02.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m data\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "data=np.array(data.iloc[:,:-1])\n",
    "target=np.array(rate_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.25896179e+01, 2.86814583e+01, 4.01416667e+02, ...,\n",
       "        2.14868056e-01, 1.14916667e-02, 2.61083333e-02],\n",
       "       [2.19823263e+01, 3.25742014e+01, 3.64996528e+02, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.19463540e+01, 3.26885069e+01, 3.55564931e+02, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [2.44305867e+01, 6.16459216e+01, 4.32795139e+02, ...,\n",
       "        1.45995323e+02, 1.23759504e+01, 2.11227295e+01],\n",
       "       [2.43397219e+01, 6.20612151e+01, 5.02240278e+02, ...,\n",
       "        1.45969539e+02, 1.23627350e+01, 2.11385033e+01],\n",
       "       [2.39779859e+01, 5.80656320e+01, 4.21691667e+02, ...,\n",
       "        1.46000695e+02, 1.23960608e+01, 2.11205538e+01]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈  련 세트 점수: 0.0032179229126565456\n",
      "테스트 세트 점수: -0.0020887010356140934\n"
     ]
    }
   ],
   "source": [
    "# 선형 모델 만들기\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 데이터셋과 테스트 데이터셋 나누기\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, random_state=42)\n",
    "\n",
    "# 모델 객체 생성 및 훈련\n",
    "lr=LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "print(\"훈  련 세트 점수:\", lr.score(x_train, y_train))\n",
    "print(\"테스트 세트 점수:\", lr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "from sklearn.utils import all_estimators\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = all_estimators(type_filter='regressor')\n",
    "\n",
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ARDRegression', sklearn.linear_model._bayes.ARDRegression),\n",
       " ('AdaBoostRegressor', sklearn.ensemble._weight_boosting.AdaBoostRegressor),\n",
       " ('BaggingRegressor', sklearn.ensemble._bagging.BaggingRegressor),\n",
       " ('BayesianRidge', sklearn.linear_model._bayes.BayesianRidge),\n",
       " ('CCA', sklearn.cross_decomposition._pls.CCA),\n",
       " ('DecisionTreeRegressor', sklearn.tree._classes.DecisionTreeRegressor),\n",
       " ('DummyRegressor', sklearn.dummy.DummyRegressor),\n",
       " ('ElasticNet', sklearn.linear_model._coordinate_descent.ElasticNet),\n",
       " ('ElasticNetCV', sklearn.linear_model._coordinate_descent.ElasticNetCV),\n",
       " ('ExtraTreeRegressor', sklearn.tree._classes.ExtraTreeRegressor),\n",
       " ('ExtraTreesRegressor', sklearn.ensemble._forest.ExtraTreesRegressor),\n",
       " ('GammaRegressor', sklearn.linear_model._glm.glm.GammaRegressor),\n",
       " ('GaussianProcessRegressor',\n",
       "  sklearn.gaussian_process._gpr.GaussianProcessRegressor),\n",
       " ('GradientBoostingRegressor', sklearn.ensemble._gb.GradientBoostingRegressor),\n",
       " ('HistGradientBoostingRegressor',\n",
       "  sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor),\n",
       " ('HuberRegressor', sklearn.linear_model._huber.HuberRegressor),\n",
       " ('IsotonicRegression', sklearn.isotonic.IsotonicRegression),\n",
       " ('KNeighborsRegressor', sklearn.neighbors._regression.KNeighborsRegressor),\n",
       " ('KernelRidge', sklearn.kernel_ridge.KernelRidge),\n",
       " ('Lars', sklearn.linear_model._least_angle.Lars),\n",
       " ('LarsCV', sklearn.linear_model._least_angle.LarsCV),\n",
       " ('Lasso', sklearn.linear_model._coordinate_descent.Lasso),\n",
       " ('LassoCV', sklearn.linear_model._coordinate_descent.LassoCV),\n",
       " ('LassoLars', sklearn.linear_model._least_angle.LassoLars),\n",
       " ('LassoLarsCV', sklearn.linear_model._least_angle.LassoLarsCV),\n",
       " ('LassoLarsIC', sklearn.linear_model._least_angle.LassoLarsIC),\n",
       " ('LinearRegression', sklearn.linear_model._base.LinearRegression),\n",
       " ('LinearSVR', sklearn.svm._classes.LinearSVR),\n",
       " ('MLPRegressor', sklearn.neural_network._multilayer_perceptron.MLPRegressor),\n",
       " ('MultiOutputRegressor', sklearn.multioutput.MultiOutputRegressor),\n",
       " ('MultiTaskElasticNet',\n",
       "  sklearn.linear_model._coordinate_descent.MultiTaskElasticNet),\n",
       " ('MultiTaskElasticNetCV',\n",
       "  sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV),\n",
       " ('MultiTaskLasso', sklearn.linear_model._coordinate_descent.MultiTaskLasso),\n",
       " ('MultiTaskLassoCV',\n",
       "  sklearn.linear_model._coordinate_descent.MultiTaskLassoCV),\n",
       " ('NuSVR', sklearn.svm._classes.NuSVR),\n",
       " ('OrthogonalMatchingPursuit',\n",
       "  sklearn.linear_model._omp.OrthogonalMatchingPursuit),\n",
       " ('OrthogonalMatchingPursuitCV',\n",
       "  sklearn.linear_model._omp.OrthogonalMatchingPursuitCV),\n",
       " ('PLSCanonical', sklearn.cross_decomposition._pls.PLSCanonical),\n",
       " ('PLSRegression', sklearn.cross_decomposition._pls.PLSRegression),\n",
       " ('PassiveAggressiveRegressor',\n",
       "  sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor),\n",
       " ('PoissonRegressor', sklearn.linear_model._glm.glm.PoissonRegressor),\n",
       " ('RadiusNeighborsRegressor',\n",
       "  sklearn.neighbors._regression.RadiusNeighborsRegressor),\n",
       " ('RandomForestRegressor', sklearn.ensemble._forest.RandomForestRegressor),\n",
       " ('RegressorChain', sklearn.multioutput.RegressorChain),\n",
       " ('Ridge', sklearn.linear_model._ridge.Ridge),\n",
       " ('RidgeCV', sklearn.linear_model._ridge.RidgeCV),\n",
       " ('SGDRegressor', sklearn.linear_model._stochastic_gradient.SGDRegressor),\n",
       " ('SVR', sklearn.svm._classes.SVR),\n",
       " ('StackingRegressor', sklearn.ensemble._stacking.StackingRegressor),\n",
       " ('TheilSenRegressor', sklearn.linear_model._theil_sen.TheilSenRegressor),\n",
       " ('TransformedTargetRegressor',\n",
       "  sklearn.compose._target.TransformedTargetRegressor),\n",
       " ('TweedieRegressor', sklearn.linear_model._glm.glm.TweedieRegressor),\n",
       " ('VotingRegressor', sklearn.ensemble._voting.VotingRegressor)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[:41]+models[43:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경고무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "scores=[]\n",
    "names=[]\n",
    "s_n=[]\n",
    "\n",
    "for name, model in models[:41]+models[43:]:\n",
    "    \n",
    "    # error 발생시 pass\n",
    "    try:\n",
    "        \n",
    "        # 모델 객체 생성\n",
    "        md=model()\n",
    "        # print(name)\n",
    "        # 학습\n",
    "        md.fit(x_train, y_train)\n",
    "        # 평가\n",
    "        score=md.score(x_test, y_test)\n",
    "        \n",
    "        # 이름과 점수 리스트에 담기\n",
    "        names.append(name)\n",
    "        scores.append(score)\n",
    "        # print(score)\n",
    "        # s_n.append((name, score)) # 이름과 점수 한번에 담기\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.323252323878428e-05,\n",
       " 3.471210724048657e-05,\n",
       " -1.9805683445062172e-05,\n",
       " -1.9805683445062172e-05,\n",
       " -9.32520622785038e-05,\n",
       " -9.325206246835194e-05,\n",
       " -9.474511840257271e-05,\n",
       " -9.474511840257271e-05,\n",
       " -9.483858430159309e-05,\n",
       " -9.783102274507627e-05,\n",
       " -0.00011808241408628461,\n",
       " -0.0003452714645579835,\n",
       " -0.0003452714645579835,\n",
       " -0.0015029304875837646,\n",
       " -0.001578068953901779,\n",
       " -0.0020884425286353814,\n",
       " -0.0020886899079979315,\n",
       " -0.0020887010356140934,\n",
       " -0.0020887010356140934,\n",
       " -0.0020887010356140934,\n",
       " -0.0020915215285055577,\n",
       " -0.0038085030583960844,\n",
       " -0.004171271857013492,\n",
       " -0.004546763839438528,\n",
       " -0.008926910210091954,\n",
       " -0.017484305802216937,\n",
       " -0.03519223821575368,\n",
       " -0.05468949760699626,\n",
       " -0.058138116056178024,\n",
       " -0.09240829383351046,\n",
       " -0.1505334251209074,\n",
       " -0.16264564919826485,\n",
       " -0.19611095888930286,\n",
       " -0.2492931685689852,\n",
       " -0.2585479102315338,\n",
       " -0.297821893208535,\n",
       " -9.529369810229065,\n",
       " -25.94751639187794,\n",
       " -2.0329922049757997e+34]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 에러 42: QuantileRegressor\n",
    "scores.sort(reverse=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링\n",
    "\n",
    "\n",
    "# # StandardScaler()\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# std = StandardScaler()\n",
    "# std.fit(x_train)\n",
    "# X_train_scaled = std.transform(x_train)\n",
    "# X_test_scaled = std.transform(x_test)\n",
    "# dtc.fit(X_train_scaled, y_train)\n",
    "# print('모델의 정확도 :', round(dtc.score(X_test_scaled, y_test), 4))\n",
    "\n",
    "\n",
    "\n",
    "# # MinMaxScaler()\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# mms = MinMaxScaler()\n",
    "# mms.fit(X_train)\n",
    "# X_train_scaled = mms.transform(X_train)\n",
    "# X_test_scaled = mms.transform(X_test)\n",
    "# dtc.fit(X_train_scaled, y_train)\n",
    "# print('모델의 정확도 :', round(dtc.score(X_test_scaled, y_test), 4))\n",
    "\n",
    "\n",
    "\n",
    "# # MaxAbsScaler()\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# mas = MaxAbsScaler()\n",
    "# mas.fit(X_train)\n",
    "# X_train_scaled = mas.transform(X_train)\n",
    "# X_test_scaled = mas.transform(X_test)\n",
    "# dtc.fit(X_train_scaled, y_train)\n",
    "# print('모델의 정확도 :', round(dtc.score(X_test_scaled, y_test), 4))\n",
    "\n",
    "\n",
    "# # RobustScaler()\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# rbs = RobustScaler()\n",
    "# X_train_scaled = rbs.fit_transform(X_train)\n",
    "# X_test_scaled = rbs.transform(X_test)\n",
    "# dtc.fit(X_train_scaled, y_train)\n",
    "# print('모델의 정확도 :', round(dtc.score(X_test_scaled, y_test), 4))\n",
    "\n",
    "\n",
    "# # Normalizer()\n",
    "# from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# norm = Normalizer()\n",
    "# X_train_scaled = norm.fit_transform(X_train)\n",
    "# X_test_scaled = norm.transform(X_test)\n",
    "# dtc.fit(X_train_scaled, y_train)\n",
    "# print('모델의 정확도 :', round(dtc.score(X_test_scaled, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경고무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "scores=[]\n",
    "\n",
    "names=[]\n",
    "s_n=[]\n",
    "\n",
    "for name, model in models[:41]+models[43:]:\n",
    "    \n",
    "    # error 발생시 pass\n",
    "    try:\n",
    "        \n",
    "        # 모델 객체 생성\n",
    "        md=model()\n",
    "        \n",
    "        # print(name)\n",
    "        # 학습\n",
    "        md.fit(x_train, y_train)\n",
    "        # 평가\n",
    "        score=md.score(x_train, y_train)\n",
    "        score2=md.score(x_test, y_test)\n",
    "        \n",
    "        # 이름과 점수 리스트에 담기\n",
    "        # names.append(name)\n",
    "        # scores.append(score)\n",
    "        # print(score)\n",
    "        s_n.append((name, score)) # 이름과 점수 한번에 담기\n",
    "        \n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DecisionTreeRegressor', 1.0),\n",
       " ('ExtraTreeRegressor', 1.0),\n",
       " ('ExtraTreesRegressor', 1.0),\n",
       " ('GaussianProcessRegressor', 1.0),\n",
       " ('GradientBoostingRegressor', 0.9459421958151728),\n",
       " ('RandomForestRegressor', 0.8201968605697008),\n",
       " ('BaggingRegressor', 0.8165122941805216),\n",
       " ('HistGradientBoostingRegressor', 0.6969217798988689),\n",
       " ('AdaBoostRegressor', 0.34778369272896836),\n",
       " ('KNeighborsRegressor', 0.21237602835678016),\n",
       " ('Lars', 0.0032179229126565456),\n",
       " ('LinearRegression', 0.0032179229126565456),\n",
       " ('TransformedTargetRegressor', 0.0032179229126565456),\n",
       " ('RidgeCV', 0.0032179228924460457),\n",
       " ('Ridge', 0.0032179228870981014),\n",
       " ('PLSRegression', 0.003203793313707348),\n",
       " ('OrthogonalMatchingPursuit', 0.0025180460123791493),\n",
       " ('OrthogonalMatchingPursuitCV', 0.0025180460123791493),\n",
       " ('KernelRidge', 0.002320516334337497),\n",
       " ('ARDRegression', 0.0023051040818169444),\n",
       " ('LassoLarsIC', 0.00217717006038598),\n",
       " ('TweedieRegressor', 0.0011869541050093524),\n",
       " ('BayesianRidge', 0.00039773674825638317),\n",
       " ('LarsCV', 0.0003199390580526096),\n",
       " ('LassoLarsCV', 0.0003199390580526096),\n",
       " ('ElasticNet', 0.00012445092277446612),\n",
       " ('Lasso', 7.839634941919638e-05),\n",
       " ('LassoCV', 6.331316502461437e-05),\n",
       " ('ElasticNetCV', 6.331316388219488e-05),\n",
       " ('DummyRegressor', 0.0),\n",
       " ('LassoLars', 0.0),\n",
       " ('NuSVR', -0.006050037143424669),\n",
       " ('SVR', -0.006360355254972916),\n",
       " ('HuberRegressor', -0.010208064357619007),\n",
       " ('TheilSenRegressor', -0.150903883731075),\n",
       " ('PassiveAggressiveRegressor', -2.769406809564818),\n",
       " ('MLPRegressor', -19.88014150027223),\n",
       " ('LinearSVR', -51.900934385683854),\n",
       " ('SGDRegressor', -2.5792679466407177e+39)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_n.sort(reverse=True,key= lambda x: x[1])\n",
    "s_n\n",
    "\n",
    "# DecisionTreeRegressor, ExtraTreeRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeRegressor, ExtraTreeRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
